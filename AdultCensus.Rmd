---
title: "Adult Census Income Prediction: A Machine Learning Approach"
subtitle: "HarvardX: PH125.9x Data Science Capstone - Choose Your Own Project"
author: "Mingyang Sun"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
geometry: margin=1in
fontsize: 11pt
header-includes:
  - \usepackage{fontspec}
  - \usepackage{unicode-math}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, 
                      fig.width = 8, fig.height = 6)

# Load required libraries
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(gbm)) install.packages("gbm", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(randomForest)
library(gbm)
```

# Introduction/Overview

## Project Goal

The primary objective of this project is to develop a machine learning
classification system that can predict whether an individual's annual
income exceeds \$50,000 based on demographic and employment
characteristics from the 1994 U.S. Census. This binary classification
problem represents a classic machine learning challenge with significant
real-world applications in economics, policy planning, and market
research.

## Dataset Overview

The Adult Census Income dataset, originally extracted from the 1994 U.S.
Census database, contains demographic information for 48,842
individuals. This dataset has become a benchmark for binary
classification algorithms and provides rich insights into socioeconomic
factors that influence income levels.

### Key Variables:

-   **Demographic features**: Age, sex, race, marital status, native
    country
-   **Education**: Education level, years of education
-   **Employment**: Work class, occupation, hours per week
-   **Financial**: Capital gains, capital losses
-   **Target variable**: Income level (≤\$50K or \>\$50K)

## Key Steps Performed

This analysis follows a comprehensive machine learning pipeline:

1.  **Data Acquisition**: Automated download from UCI Machine Learning
    Repository
2.  **Exploratory Data Analysis**: Understanding patterns and
    relationships in the data
3.  **Data Preprocessing**: Cleaning, feature engineering, and
    transformation
4.  **Model Development**: Implementation of three distinct algorithms
5.  **Model Evaluation**: Comparison using multiple performance metrics
6.  **Final Testing**: Evaluation on holdout test set

## Executive Summary

Three machine learning algorithms were implemented and compared:
Logistic Regression, Random Forest, and k-Nearest Neighbors (KNN). The
analysis revealed that **Gradient Boosting** achieved the highest performance
with a test accuracy of **0.8649**, demonstrating that
demographic and employment factors can effectively predict income levels
with practical accuracy.

```{r data-loading, include=FALSE}
# Data loading and preprocessing using Kaggle dataset
temp_file <- "archive.zip"
if(!file.exists(temp_file))
  download.file("https://www.kaggle.com/api/v1/datasets/download/uciml/adult-census-income", temp_file)

# Extract and read the data files
unzip(temp_file, exdir = "data")

# Read the dataset (Kaggle version has headers)
combined_data <- read.csv("data/adult.csv", stringsAsFactors = FALSE, na.strings = c("?", " ?"))

# Clean up extracted files and zip
unlink("data", recursive = TRUE)
file.remove(temp_file)

# Preprocessing
adult_clean <- combined_data

# Handle missing values
categorical_vars <- c("workclass", "occupation", "native.country")
for(var in categorical_vars) {
  if(sum(is.na(adult_clean[[var]])) > 0) {
    mode_val <- names(sort(table(adult_clean[[var]]), decreasing = TRUE))[1]
    adult_clean[[var]][is.na(adult_clean[[var]])] <- mode_val
  }
}

# Convert income to binary factor (Kaggle uses different format)
adult_clean$income <- factor(ifelse(adult_clean$income == ">50K", 1, 0), 
                            levels = c(0, 1), labels = c("<=50K", ">50K"))

# Convert categorical variables to factors (adjust for Kaggle column names)
categorical_cols <- c("workclass", "education", "marital.status", "occupation", 
                     "relationship", "race", "sex", "native.country")
for(col in categorical_cols) {
  if(col %in% names(adult_clean)) {
    adult_clean[[col]] <- as.factor(adult_clean[[col]])
  }
}

# Feature engineering (adjust for Kaggle column names)
adult_clean$age_group <- cut(adult_clean$age, 
                            breaks = c(0, 25, 35, 45, 55, 65, 100),
                            labels = c("18-25", "26-35", "36-45", "46-55", "56-65", "65+"))

adult_clean$has_capital_gain <- factor(ifelse(adult_clean$capital.gain > 0, "Yes", "No"))
adult_clean$has_capital_loss <- factor(ifelse(adult_clean$capital.loss > 0, "Yes", "No"))
adult_clean$net_capital <- adult_clean$capital.gain - adult_clean$capital.loss

adult_clean$work_hours_category <- cut(adult_clean$hours.per.week,
                                      breaks = c(0, 20, 40, 60, 100),
                                      labels = c("Part-time", "Full-time", "Overtime", "Excessive"))

adult_clean$education_level <- case_when(
  adult_clean$education %in% c("Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", 
                               "10th", "11th", "12th") ~ "No_HS_Diploma",
  adult_clean$education %in% c("HS-grad", "Some-college") ~ "HS_Some_College",
  adult_clean$education %in% c("Assoc-voc", "Assoc-acdm") ~ "Associate",
  adult_clean$education == "Bachelors" ~ "Bachelors",
  adult_clean$education %in% c("Masters", "Prof-school", "Doctorate") ~ "Advanced"
)
adult_clean$education_level <- factor(adult_clean$education_level, 
                                     levels = c("No_HS_Diploma", "HS_Some_College", 
                                               "Associate", "Bachelors", "Advanced"))

# Create aliases for variables with different names in Kaggle dataset
if("education.num" %in% names(adult_clean)) {
  adult_clean$education_num <- adult_clean$education.num
}
if("hours.per.week" %in% names(adult_clean)) {
  adult_clean$hours_per_week <- adult_clean$hours.per.week
}
if("marital.status" %in% names(adult_clean)) {
  adult_clean$marital_status <- adult_clean$marital.status
}
if("native.country" %in% names(adult_clean)) {
  adult_clean$native_country <- adult_clean$native.country
}
if("capital.gain" %in% names(adult_clean)) {
  adult_clean$capital_gain <- adult_clean$capital.gain
}
if("capital.loss" %in% names(adult_clean)) {
  adult_clean$capital_loss <- adult_clean$capital.loss
}
```

# Methods/Analysis

## Data Cleaning and Preparation

### Dataset Characteristics

```{r dataset-summary}
# Create dataset summary table
cat("Dataset Summary:\n")
cat("Total Observations:", nrow(combined_data), "\n")
cat("Number of Features:", ncol(combined_data) - 1, "\n")
cat("Target Classes: 2 (Binary Classification)\n")
cat("Missing Values:", sum(is.na(combined_data)), "\n")
cat("Data Types: Mixed (Numeric & Categorical)\n")
```

### Missing Data Analysis

The dataset contained missing values in three categorical variables:
workclass, occupation, and native_country. These were handled using mode
imputation, which is appropriate for categorical data and maintains the
original distribution patterns.

```{r missing-data}
# Missing data analysis
cat("Missing Values by Column:\n")
missing_counts <- sapply(combined_data, function(x) sum(is.na(x)))
missing_vars <- missing_counts[missing_counts > 0]
if(length(missing_vars) > 0) {
  for(i in 1:length(missing_vars)) {
    cat(names(missing_vars)[i], ":", missing_vars[i], 
        "(", round(missing_vars[i] / nrow(combined_data) * 100, 2), "%)\n")
  }
} else {
  cat("No missing values found.\n")
}
```

## Data Exploration and Visualization

### Target Variable Distribution

```{r income-distribution, fig.cap="Distribution of Income Classes"}
income_dist <- table(adult_clean$income)
income_df <- data.frame(
  Income = names(income_dist),
  Count = as.numeric(income_dist),
  Percentage = round(as.numeric(income_dist) / sum(income_dist) * 100, 1)
)

ggplot(income_df, aes(x = Income, y = Count, fill = Income)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(Count, "\n(", Percentage, "%)")), 
            vjust = -0.5, size = 4) +
  scale_fill_manual(values = c("<=50K" = "coral", ">50K" = "steelblue")) +
  labs(title = "Distribution of Income Classes",
       x = "Income Level", y = "Number of Individuals") +
  theme_minimal() +
  theme(legend.position = "none")
```

The dataset shows a significant class imbalance, with approximately 76%
of individuals earning ≤\$50K and 24% earning \>\$50K. This imbalance is
typical of real-world income distributions and will be considered in
model evaluation.

### Age Analysis

```{r age-analysis, fig.cap="Age Distribution by Income Level"}
ggplot(adult_clean, aes(x = age, fill = income)) +
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  scale_fill_manual(values = c("<=50K" = "coral", ">50K" = "steelblue")) +
  labs(title = "Age Distribution by Income Level",
       x = "Age", y = "Count", fill = "Income Level") +
  theme_minimal() +
  facet_wrap(~income, scales = "free_y")
```

```{r age-stats}
# Age statistics by income
cat("Age Statistics by Income Level:\n")
age_stats <- adult_clean %>%
  group_by(income) %>%
  summarise(
    Mean_Age = round(mean(age), 1),
    Median_Age = median(age),
    Min_Age = min(age),
    Max_Age = max(age),
    .groups = 'drop'
  )
print(age_stats)
```

### Education Impact Analysis

```{r education-analysis, fig.cap="Education Level vs Income"}
education_income <- adult_clean %>%
  group_by(education_level, income) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(education_level) %>%
  mutate(
    total = sum(count),
    percentage = round(count / total * 100, 1)
  ) %>%
  filter(income == ">50K")

ggplot(education_income, aes(x = education_level, y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  geom_text(aes(label = paste0(percentage, "%")), vjust = -0.5) +
  labs(title = "Percentage Earning >$50K by Education Level",
       x = "Education Level", y = "Percentage Earning >$50K") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The analysis reveals a strong positive correlation between education
level and high income probability, with advanced degree holders having
the highest likelihood of earning \>\$50K.

### Work Hours Analysis

```{r work-hours, fig.cap="Work Hours Distribution by Income"}
ggplot(adult_clean, aes(x = work_hours_category, fill = income)) +
  geom_bar(position = "fill", alpha = 0.8) +
  scale_fill_manual(values = c("<=50K" = "coral", ">50K" = "steelblue")) +
  labs(title = "Work Hours Category vs Income Distribution",
       x = "Work Hours Category", y = "Proportion", fill = "Income Level") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Gender and Marital Status Analysis

```{r demographic-analysis-1, fig.cap="Income Distribution by Demographics"}
# Gender analysis
gender_plot <- adult_clean %>%
  group_by(sex, income) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(sex) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  filter(income == ">50K") %>%
  ggplot(aes(x = sex, y = percentage, fill = sex)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), vjust = -0.5) +
  labs(title = "% Earning >$50K by Gender", x = "Gender", y = "Percentage") +
  theme_minimal() +
  theme(legend.position = "none")

print(gender_plot)

```

```{r demographic-analysis-2, fig.cap="Income Distribution by Demographics"}

# Marital status analysis
marital_plot <- adult_clean %>%
  group_by(marital_status, income) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(marital_status) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  filter(income == ">50K") %>%
  ggplot(aes(x = marital_status, y = percentage, fill = marital_status)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  labs(title = "% Earning >$50K by Marital Status", 
       x = "Marital Status", y = "Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

print(marital_plot)

```

## Feature Engineering

Several new features were created to enhance model performance:

1.  **Age Groups**: Categorical age brackets for better pattern
    recognition
2.  **Capital Features**: Binary indicators for capital gains/losses
    presence
3.  **Net Capital**: Difference between capital gains and losses
4.  **Work Hours Categories**: Grouped working hours into meaningful
    segments
5.  **Education Levels**: Simplified education categories for better
    interpretability

## Modeling Approach

### Data Splitting Strategy

The dataset was partitioned using a three-way split approach: -
**Training Set (64%)**: Used for model training - **Validation Set
(16%)**: Used for model selection and hyperparameter tuning - **Test Set
(20%)**: Reserved for final evaluation only

```{r data-split, include=FALSE}
# Data splitting (same as script)
set.seed(123)
train_index <- createDataPartition(adult_clean$income, p = 0.8, list = FALSE)
train_data <- adult_clean[train_index, ]
test_data <- adult_clean[-train_index, ]

val_index <- createDataPartition(train_data$income, p = 0.2, list = FALSE)
validation_data <- train_data[val_index, ]
train_data_final <- train_data[-val_index, ]
```

```{r split-summary}
cat("Data Split Summary:\n")
cat("Training Set:", nrow(train_data_final), "observations (", 
    round(nrow(train_data_final) / nrow(adult_clean) * 100, 1), "%)\n")
cat("Validation Set:", nrow(validation_data), "observations (", 
    round(nrow(validation_data) / nrow(adult_clean) * 100, 1), "%)\n")
cat("Test Set:", nrow(test_data), "observations (", 
    round(nrow(test_data) / nrow(adult_clean) * 100, 1), "%)\n")
```

### Model Development Strategy

Three distinct machine learning algorithms were implemented to capture
different aspects of the data:

#### Model 1: Logistic Regression

A linear classifier that models the log-odds of high income as a linear
combination of features. This provides interpretable coefficients and
serves as a baseline model.

**Mathematical Formula:**
$\log\left(\frac{P(income > 50K)}{1 - P(income > 50K)}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n$

#### Model 2: Random Forest

An ensemble method that combines multiple decision trees using bootstrap
aggregating (bagging). This captures non-linear relationships and
feature interactions.

**Key Parameters:** - Number of trees: 500 - Variables per split: 4 -
Importance calculation: Enabled

#### Model 3: Gradient Boosting Machine (GBM)

A sequential ensemble method that builds models iteratively, with each
new model correcting errors from previous models.

**Key Parameters:** - Number of trees: 1000 (with early stopping) -
Interaction depth: 4 - Learning rate: 0.01 - Cross-validation folds: 5

## Model Training and Validation

```{r model-training, include=FALSE}
# Model training (simplified version)
# Evaluation function
evaluate_model <- function(predictions, actual) {
  predictions <- factor(predictions, levels = levels(actual))
  cm <- confusionMatrix(predictions, actual)
  
  return(list(
    accuracy = cm$overall['Accuracy'],
    sensitivity = cm$byClass['Sensitivity'],
    specificity = cm$byClass['Specificity'],
    precision = cm$byClass['Pos Pred Value'],
    f1_score = cm$byClass['F1']
  ))
}

# Model 1: Logistic Regression
key_vars <- c("age", "education_num", "hours_per_week", "sex", "marital_status", 
              "education_level", "work_hours_category", "has_capital_gain", "net_capital")
formula_lr <- as.formula(paste("income ~", paste(key_vars, collapse = " + ")))
lr_model <- glm(formula_lr, data = train_data_final, family = "binomial")
lr_pred_prob <- predict(lr_model, validation_data, type = "response")
lr_pred <- factor(ifelse(lr_pred_prob > 0.5, ">50K", "<=50K"), levels = c("<=50K", ">50K"))
lr_eval <- evaluate_model(lr_pred, validation_data$income)

# Model 2: Random Forest
rf_vars <- c("age", "workclass", "education_num", "marital_status", "occupation",
             "relationship", "race", "sex", "hours_per_week", "education_level",
             "work_hours_category", "has_capital_gain", "has_capital_loss", "net_capital")
train_rf <- train_data_final[, c(rf_vars, "income")]
validation_rf <- validation_data[, c(rf_vars, "income")]
set.seed(123)
rf_model <- randomForest(income ~ ., data = train_rf, ntree = 500, mtry = 4, importance = TRUE)
rf_pred <- predict(rf_model, validation_rf)
rf_eval <- evaluate_model(rf_pred, validation_data$income)

# Model 3: GBM
train_gbm <- train_data_final[, c(rf_vars, "income")]
validation_gbm <- validation_data[, c(rf_vars, "income")]
train_gbm$income_numeric <- as.numeric(train_gbm$income) - 1
validation_gbm$income_numeric <- as.numeric(validation_gbm$income) - 1
set.seed(123)
gbm_model <- gbm(income_numeric ~ . - income, data = train_gbm,
                distribution = "bernoulli", n.trees = 1000, 
                interaction.depth = 4, shrinkage = 0.01, cv.folds = 5)
optimal_trees <- gbm.perf(gbm_model, method = "cv", plot.it = FALSE)
gbm_pred_prob <- predict(gbm_model, validation_gbm, n.trees = optimal_trees, type = "response")
gbm_pred <- factor(ifelse(gbm_pred_prob > 0.5, ">50K", "<=50K"), levels = c("<=50K", ">50K"))
gbm_eval <- evaluate_model(gbm_pred, validation_data$income)

# Store results
model_results <- data.frame(
  Model = c("Logistic Regression", "Random Forest", "Gradient Boosting"),
  Accuracy = c(lr_eval$accuracy, rf_eval$accuracy, gbm_eval$accuracy),
  Sensitivity = c(lr_eval$sensitivity, rf_eval$sensitivity, gbm_eval$sensitivity),
  Specificity = c(lr_eval$specificity, rf_eval$specificity, gbm_eval$specificity),
  F1_Score = c(lr_eval$f1_score, rf_eval$f1_score, gbm_eval$f1_score)
)

# Select best model
best_model_idx <- which.max(model_results$Accuracy)
best_model_name <- model_results$Model[best_model_idx]
```

# Results

## Model Performance Comparison

```{r model-comparison}
cat("Model Performance Comparison on Validation Set:\n")
# Round only the numeric columns
results_display <- model_results
results_display[, 2:5] <- round(results_display[, 2:5], 4)
print(results_display)

# Highlight best model
best_model_idx <- which.max(model_results$Accuracy)
cat("\nBest performing model:", model_results$Model[best_model_idx], "\n")
cat("Best accuracy:", round(model_results$Accuracy[best_model_idx], 4), "\n")
```

```{r performance-visualization, fig.cap="Model Performance Comparison"}
model_long <- model_results %>%
  pivot_longer(cols = c(Accuracy, Sensitivity, Specificity, F1_Score),
               names_to = "Metric", values_to = "Value")

ggplot(model_long, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  labs(title = "Model Performance Comparison",
       x = "Model", y = "Score") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(0, 1)
```

## Feature Importance Analysis

```{r feature-importance, fig.cap="Top 10 Most Important Features (Random Forest)"}
# Random Forest feature importance
importance_rf <- importance(rf_model)
importance_df <- data.frame(
  Variable = rownames(importance_rf),
  Importance = importance_rf[, "MeanDecreaseGini"]
) %>%
  arrange(desc(Importance)) %>%
  head(10) %>%
  mutate(Variable = reorder(Variable, Importance))

ggplot(importance_df, aes(x = Variable, y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  coord_flip() +
  labs(title = "Top 10 Most Important Features (Random Forest)",
       x = "Features", y = "Mean Decrease in Gini") +
  theme_minimal()
```

The feature importance analysis reveals that **marital status**,
**age**, and **education level** are the most predictive factors for
income classification, followed by **hours per week** and
**occupation**.

## Final Model Evaluation

```{r final-evaluation, include=FALSE}
# Final evaluation on test set
best_model_name <- model_results$Model[which.max(model_results$Accuracy)]

if(best_model_name == "Logistic Regression") {
  final_pred_prob <- predict(lr_model, test_data, type = "response")
  final_pred <- factor(ifelse(final_pred_prob > 0.5, ">50K", "<=50K"), levels = c("<=50K", ">50K"))
} else if(best_model_name == "Random Forest") {
  test_rf <- test_data[, c(rf_vars, "income")]
  final_pred <- predict(rf_model, test_rf)
} else if(best_model_name == "Gradient Boosting") {
  test_gbm <- test_data[, c(rf_vars, "income")]
  final_pred_prob <- predict(gbm_model, test_gbm, n.trees = optimal_trees, type = "response")
  final_pred <- factor(ifelse(final_pred_prob > 0.5, ">50K", "<=50K"), levels = c("<=50K", ">50K"))
} else {
  # Fallback to Random Forest if no match
  test_rf <- test_data[, c(rf_vars, "income")]
  final_pred <- predict(rf_model, test_rf)
}

# Ensure final_pred exists before evaluation
if(exists("final_pred")) {
  final_eval <- evaluate_model(final_pred, test_data$income)
  final_cm <- confusionMatrix(final_pred, test_data$income)
} else {
  stop("Error: final_pred could not be created")
}
```

Based on validation performance, **`r best_model_name`** was selected as
the final model and evaluated on the holdout test set.

```{r final-results}
cat("Final Model Performance on Test Set -", best_model_name, ":\n")
cat("Accuracy:", round(final_eval$accuracy, 4), "\n")
cat("Sensitivity:", round(final_eval$sensitivity, 4), "\n")
cat("Specificity:", round(final_eval$specificity, 4), "\n")
cat("Precision:", round(final_eval$precision, 4), "\n")
cat("F1 Score:", round(final_eval$f1_score, 4), "\n")
```

```{r confusion-matrix}
# Confusion Matrix
cat("Confusion Matrix - Test Set Results:\n")
cm_table <- final_cm$table
print(cm_table)
```

## Model Interpretation

### Key Findings:

1.  **Education Impact**: Advanced education significantly increases the
    probability of high income, with each additional education level
    substantially improving the odds.

2.  **Age Factor**: Income potential peaks in middle age (35-55),
    reflecting career advancement and experience accumulation.

3.  **Work Hours**: Individuals working more than 40 hours per week show
    substantially higher income probabilities.

4.  **Marital Status**: Married individuals demonstrate higher income
    rates, likely reflecting traditional household income patterns.

5.  **Occupation Type**: Professional and managerial occupations
    strongly predict high income levels.

# Conclusion

## Summary of Findings

This project successfully developed and evaluated three machine learning
models for predicting individual income levels based on census
demographic data. The **`r best_model_name`** model achieved the best
performance with a test accuracy of
**`r round(final_eval$accuracy, 4)`**, demonstrating that demographic
and employment characteristics can effectively predict income
classification.

### Key Technical Achievements:

-   **Comprehensive Data Pipeline**: Implemented automated data
    acquisition, cleaning, and preprocessing
-   **Feature Engineering**: Created meaningful derived features that
    improved model performance
-   **Model Diversity**: Successfully implemented three distinct
    algorithms with different learning approaches
-   **Rigorous Evaluation**: Used proper train/validation/test splits to
    ensure unbiased performance assessment

### Analytical Insights:

-   **Education remains the strongest predictor** of high income, with
    advanced degrees providing substantial advantage
-   **Work hours and age** show strong relationships with income
    potential
-   **Demographic factors** like marital status continue to influence
    income patterns
-   **Occupation type** serves as a crucial mediating factor between
    education and income

## Limitations

Several limitations should be considered when interpreting these
results:

### **Data Limitations**:

1.  **Temporal Constraints**: Data from 1994 may not reflect current
    economic realities
2.  **Geographic Scope**: Limited to U.S. census data, reducing global
    applicability
3.  **Feature Completeness**: Missing potentially important factors
    like:
    -   Industry type and company size
    -   Geographic location details
    -   Economic conditions and market factors

### **Methodological Limitations**:

1.  **Class Imbalance**: The 76/24 split may bias predictions toward the
    majority class
2.  **Feature Selection**: Manual feature engineering may miss optimal
    combinations
3.  **Model Assumptions**: Each algorithm makes specific assumptions
    about data relationships
4.  **Causality**: Models show correlation, not causation between
    features and income

### **Generalization Concerns**:

1.  **Demographic Shifts**: Population characteristics have changed
    significantly since 1994
2.  **Economic Evolution**: Technology and globalization have
    transformed the job market
3.  **Social Changes**: Gender roles and family structures have evolved
    substantially

# References

1.  Dua, D. and Graff, C. (2019). UCI Machine Learning Repository
    [<http://archive.ics.uci.edu/ml>]. Irvine, CA: University of
    California, School of Information and Computer Science.

------------------------------------------------------------------------

**Final Model: `r best_model_name`**

**Test Set Performance: `r round(final_eval$accuracy, 4)` Accuracy**
